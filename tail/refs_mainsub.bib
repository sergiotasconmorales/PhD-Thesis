
% ------------------------------------------------------------------------------------
% Consistency-preserving Visual Question Answering in Medical Imaging

@article{kil2021discovering,
  title={Discovering the Unknown Knowns: Turning Implicit Knowledge in the Dataset into Explicit Training Examples for Visual Question Answering},
  author={Kil, Jihyung and Zhang, Cheng and Xuan, Dong and Chao, Wei-Lun},
  journal={arXiv preprint arXiv:2109.06122},
  year={2021}
}






@inproceedings{niu2021counterfactual,
  title={Counterfactual vqa: A cause-effect look at language bias},
  author={Niu, Yulei and Tang, Kaihua and Zhang, Hanwang and Lu, Zhiwu and Hua, Xian-Sheng and Wen, Ji-Rong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12700--12710},
  year={2021}
}

@inproceedings{kv2020reducing,
  title={Reducing language biases in visual question answering with visually-grounded question encoder},
  author={KV, Gouthaman and Mittal, Anurag},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XIII 16},
  pages={18--34},
  year={2020},
  organization={Springer}
}

@article{ramakrishnan2018overcoming,
  title={Overcoming language priors in visual question answering with adversarial regularization},
  author={Ramakrishnan, Sainandan and Agrawal, Aishwarya and Lee, Stefan},
  journal={arXiv preprint arXiv:1810.03649},
  year={2018}
}



@article{clark2019don,
  title={Don't take the easy way out: Ensemble based methods for avoiding known dataset biases},
  author={Clark, Christopher and Yatskar, Mark and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1909.03683},
  year={2019}
}

@article{jiang2018pythia,
  title={Pythia v0. 1: the winning entry to the vqa challenge 2018},
  author={Jiang, Yu and Natarajan, Vivek and Chen, Xinlei and Rohrbach, Marcus and Batra, Dhruv and Parikh, Devi},
  journal={arXiv preprint arXiv:1807.09956},
  year={2018}
}

@inproceedings{zhou2020unified,
  title={Unified vision-language pre-training for image captioning and vqa},
  author={Zhou, Luowei and Palangi, Hamid and Zhang, Lei and Hu, Houdong and Corso, Jason and Gao, Jianfeng},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={07},
  pages={13041--13049},
  year={2020}
}

@inproceedings{abacha2018nlm,
  title={NLM at ImageCLEF 2018 Visual Question Answering in the Medical Domain.},
  author={Abacha, Asma Ben and Gayen, Soumya and Lau, Jason J and Rajaraman, Sivaramakrishnan and Demner-Fushman, Dina},
  booktitle={CLEF (Working Notes)},
  year={2018}
}
@inproceedings{zhou2018employing,
  title={Employing Inception-Resnet-v2 and Bi-LSTM for Medical Domain Visual Question Answering.},
  author={Zhou, Yangyang and Kang, Xin and Ren, Fuji},
  booktitle={CLEF (Working Notes)},
  year={2018}
}

@article{kornuta2019leveraging,
  title={Leveraging medical visual question answering with supporting facts},
  author={Kornuta, Tomasz and Rajan, Deepta and Shivade, Chaitanya and Asseman, Alexis and Ozcan, Ahmet S},
  journal={arXiv preprint arXiv:1905.12008},
  year={2019}
}



@inproceedings{wang2021image,
  title={Image Classification with Consistent Supporting Evidence},
  author={Wang, Peiqi and Liao, Ruizhi and Moyer, Daniel and Berkowitz, Seth and Horng, Steven and Golland, Polina},
  booktitle={Machine Learning for Health},
  pages={168--180},
  year={2021},
  organization={PMLR}
}