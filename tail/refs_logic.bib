
% CVPR2023 paper

@inproceedings{tascon2023logical,
  title={Logical Implications for Visual Question Answering Consistency},
  author={Tascon-Morales, Sergio and M{\'a}rquez-Neila, Pablo and Sznitman, Raphael},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6725--6735},
  year={2023}
}


@String(PAMI = {IEEE Trans. Pattern Anal. Mach. Intell.})
@String(IJCV = {Int. J. Comput. Vis.})
@String(CVPR= {IEEE Conf. Comput. Vis. Pattern Recog.})
@String(ICCV= {Int. Conf. Comput. Vis.})
@String(ECCV= {Eur. Conf. Comput. Vis.})
@String(NIPS= {Adv. Neural Inform. Process. Syst.})
@String(ICPR = {Int. Conf. Pattern Recog.})
@String(BMVC= {Brit. Mach. Vis. Conf.})
@String(TOG= {ACM Trans. Graph.})
@String(TIP  = {IEEE Trans. Image Process.})
@String(TVCG  = {IEEE Trans. Vis. Comput. Graph.})
@String(TMM  = {IEEE Trans. Multimedia})
@String(ACMMM= {ACM Int. Conf. Multimedia})
@String(ICME = {Int. Conf. Multimedia and Expo})
@String(ICASSP=	{ICASSP})
@String(ICIP = {IEEE Int. Conf. Image Process.})
@String(ACCV  = {ACCV})
@String(ICLR = {Int. Conf. Learn. Represent.})
@String(IJCAI = {IJCAI})
@String(PR   = {Pattern Recognition})
@String(AAAI = {AAAI})
@String(CVPRW= {IEEE Conf. Comput. Vis. Pattern Recog. Worksh.})
@String(CSVT = {IEEE Trans. Circuit Syst. Video Technol.})

@String(SPL	= {IEEE Sign. Process. Letters})
@String(VR   = {Vis. Res.})
@String(JOV	 = {J. Vis.})
@String(TVC  = {The Vis. Comput.})
@String(JCST  = {J. Comput. Sci. Tech.})
@String(CGF  = {Comput. Graph. Forum})
@String(CVM = {Computational Visual Media})


@String(PAMI  = {IEEE TPAMI})
@String(IJCV  = {IJCV})
@String(CVPR  = {CVPR})
@String(ICCV  = {ICCV})
@String(ECCV  = {ECCV})
@String(NIPS  = {NeurIPS})
@String(ICPR  = {ICPR})
@String(BMVC  =	{BMVC})
@String(TOG   = {ACM TOG})
@String(TIP   = {IEEE TIP})
@String(TVCG  = {IEEE TVCG})
@String(TCSVT = {IEEE TCSVT})
@String(TMM   =	{IEEE TMM})
@String(ACMMM = {ACM MM})
@String(ICME  =	{ICME})
@String(ICASSP=	{ICASSP})
@String(ICIP  = {ICIP})
@String(ACCV  = {ACCV})
@String(ICLR  = {ICLR})
@String(IJCAI = {IJCAI})
@String(PR = {PR})
@String(AAAI = {AAAI})
@String(CVPRW= {CVPRW})
@String(CSVT = {IEEE TCSVT})


%% About VQA in general

%% About previous works on consistency in VQA


@inproceedings{jing2022maintaining,
  title={Maintaining Reasoning Consistency in Compositional Visual Question Answering},
  author={Jing, Chenchen and Jia, Yunde and Wu, Yuwei and Liu, Xinyu and Wu, Qi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5099--5108},
  year={2022}
}



@book{bradley1979possible,
  title={Possible Worlds: An Introduction to Logic and Its Philosophy},
  author={Bradley, R. and Swartz, N.},
  isbn={9780631161400},
  lccn={lc85672970},
  url={https://books.google.ch/books?id=x353QgAACAAJ},
  year={1979},
  publisher={B. Blackwell}
}

@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}

@article{young2014image,
  title={From image descriptions to visual denotations: New similarity metrics for semantic inference over event descriptions},
  author={Young, Peter and Lai, Alice and Hodosh, Micah and Hockenmaier, Julia},
  journal={Transactions of the Association for Computational Linguistics},
  volume={2},
  pages={67--78},
  year={2014},
  publisher={MIT Press}
}



@inproceedings{nam2017dual,
  title={Dual attention networks for multimodal reasoning and matching},
  author={Nam, Hyeonseob and Ha, Jung-Woo and Kim, Jeonghee},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={299--307},
  year={2017}
}

@inproceedings{cadene2019murel,
  title={Murel: Multimodal relational reasoning for visual question answering},
  author={Cadene, Remi and Ben-Younes, Hedi and Cord, Matthieu and Thome, Nicolas},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={1989--1998},
  year={2019}
}

@article{kim2018bilinear,
  title={Bilinear attention networks},
  author={Kim, Jin-Hwa and Jun, Jaehyun and Zhang, Byoung-Tak},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018}
}

@inproceedings{gurari2018vizwiz,
  title={Vizwiz grand challenge: Answering visual questions from blind people},
  author={Gurari, Danna and Li, Qing and Stangl, Abigale J and Guo, Anhong and Lin, Chi and Grauman, Kristen and Luo, Jiebo and Bigham, Jeffrey P},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3608--3617},
  year={2018}
}

@inproceedings{gurari2019vizwiz,
  title={Vizwiz-priv: A dataset for recognizing the presence and purpose of private visual information in images taken by blind people},
  author={Gurari, Danna and Li, Qing and Lin, Chi and Zhao, Yinan and Guo, Anhong and Stangl, Abigale and Bigham, Jeffrey P},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={939--948},
  year={2019}
}


@inproceedings{nguyen2019overcoming,
  title={Overcoming data limitation in medical visual question answering},
  author={Nguyen, Binh D and Do, Thanh-Toan and Nguyen, Binh X and Do, Tuong and Tjiputra, Erman and Tran, Quang D},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={522--530},
  year={2019},
  organization={Springer}
}



@inproceedings{chen2022grounding,
  title={Grounding Answers for Visual Questions Asked by Visually Impaired People},
  author={Chen, Chongyan and Anjum, Samreen and Gurari, Danna},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={19098--19107},
  year={2022}
}



@inproceedings{han2021greedy,
  title={Greedy gradient ensemble for robust visual question answering},
  author={Han, Xinzhe and Wang, Shuhui and Su, Chi and Huang, Qingming and Tian, Qi},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1584--1593},
  year={2021}
}

@inproceedings{banerjee2021weakly,
  title={Weakly Supervised Relative Spatial Reasoning for Visual Question Answering},
  author={Banerjee, Pratyay and Gokhale, Tejas and Yang, Yezhou and Baral, Chitta},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1908--1918},
  year={2021}
}
@inproceedings{cao2021linguistically,
  title={Linguistically routing capsule network for out-of-distribution visual question answering},
  author={Cao, Qingxing and Wan, Wentao and Wang, Keze and Liang, Xiaodan and Lin, Liang},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1614--1623},
  year={2021}
}

@inproceedings{dancette2021beyond,
  title={Beyond question-based biases: Assessing multimodal shortcut learning in visual question answering},
  author={Dancette, Corentin and Cadene, Remi and Teney, Damien and Cord, Matthieu},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1574--1583},
  year={2021}
}

@article{teney2020unshuffling,
  title={Unshuffling data for improved generalization},
  author={Teney, Damien and Abbasnejad, Ehsan and Hengel, Anton van den},
  journal={arXiv preprint arXiv:2002.11894},
  year={2020}
}

@inproceedings{yang2021auto,
  title={Auto-parsing network for image captioning and visual question answering},
  author={Yang, Xu and Gao, Chongyang and Zhang, Hanwang and Cai, Jianfei},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2197--2207},
  year={2021}
}

@inproceedings{zhou2021trar,
  title={Trar: Routing the attention spans in transformer for visual question answering},
  author={Zhou, Yiyi and Ren, Tianhe and Zhu, Chaoyang and Sun, Xiaoshuai and Liu, Jianzhuang and Ding, Xinghao and Xu, Mingliang and Ji, Rongrong},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={2074--2084},
  year={2021}
}

@inproceedings{ding2022mukea,
  title={MuKEA: Multimodal Knowledge Extraction and Accumulation for Knowledge-based Visual Question Answering},
  author={Ding, Yang and Yu, Jing and Liu, Bang and Hu, Yue and Cui, Mingxin and Wu, Qi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5089--5098},
  year={2022}
}

@inproceedings{gao2022transform,
  title={Transform-Retrieve-Generate: Natural Language-Centric Outside-Knowledge Visual Question Answering},
  author={Gao, Feng and Ping, Qing and Thattai, Govind and Reganti, Aishwarya and Wu, Ying Nian and Natarajan, Prem},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5067--5077},
  year={2022}
}

@inproceedings{gupta2022swapmix,
  title={Swapmix: Diagnosing and regularizing the over-reliance on visual context in visual question answering},
  author={Gupta, Vipul and Li, Zhuowan and Kortylewski, Adam and Zhang, Chenyu and Li, Yingwei and Yuille, Alan},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5078--5088},
  year={2022}
}

@inproceedings{walmer2022dual,
  title={Dual-Key Multimodal Backdoors for Visual Question Answering},
  author={Walmer, Matthew and Sikka, Karan and Sur, Indranil and Shrivastava, Abhinav and Jha, Susmit},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={15375--15385},
  year={2022}
}

@inproceedings{agarwal2020towards,
  title={Towards causal vqa: Revealing and reducing spurious correlations by invariant and covariant semantic editing},
  author={Agarwal, Vedika and Shetty, Rakshith and Fritz, Mario},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={9690--9698},
  year={2020}
}

@inproceedings{chen2020counterfactual,
  title={Counterfactual samples synthesizing for robust visual question answering},
  author={Chen, Long and Yan, Xin and Xiao, Jun and Zhang, Hanwang and Pu, Shiliang and Zhuang, Yueting},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10800--10809},
  year={2020}
}

@inproceedings{abbasnejad2020counterfactual,
  title={Counterfactual vision and language learning},
  author={Abbasnejad, Ehsan and Teney, Damien and Parvaneh, Amin and Shi, Javen and Hengel, Anton van den},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={10044--10054},
  year={2020}
}

@article{wang2015explicit,
  title={Explicit knowledge-based reasoning for visual question answering},
  author={Wang, Peng and Wu, Qi and Shen, Chunhua and Hengel, Anton van den and Dick, Anthony},
  journal={arXiv preprint arXiv:1511.02570},
  year={2015}
}

@article{wu2021multi,
  title={Multi-scale relation reasoning for multi-modal Visual Question Answering},
  author={Wu, Yirui and Ma, Yuntao and Wan, Shaohua},
  journal={Signal Processing: Image Communication},
  volume={96},
  pages={116319},
  year={2021},
  publisher={Elsevier}
}

@article{he2020pathvqa,
  title={Pathvqa: 30000+ questions for medical visual question answering},
  author={He, Xuehai and Zhang, Yichen and Mou, Luntian and Xing, Eric and Xie, Pengtao},
  journal={arXiv preprint arXiv:2003.10286},
  year={2020}
}

@article{lau2018dataset,
  title={A dataset of clinically generated visual questions and answers about radiology images},
  author={Lau, Jason J and Gayen, Soumya and Ben Abacha, Asma and Demner-Fushman, Dina},
  journal={Scientific data},
  volume={5},
  number={1},
  pages={1--10},
  year={2018},
  publisher={Nature Publishing Group}
}



@inproceedings{maccartney2008modeling,
  title={Modeling semantic containment and exclusion in natural language inference},
  author={MacCartney, Bill and Manning, Christopher D},
  booktitle={Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008)},
  pages={521--528},
  year={2008}
}

@article{williams2017broad,
  title={A broad-coverage challenge corpus for sentence understanding through inference},
  author={Williams, Adina and Nangia, Nikita and Bowman, Samuel R},
  journal={arXiv preprint arXiv:1704.05426},
  year={2017}
}

@article{wang2019superglue,
  title={Superglue: A stickier benchmark for general-purpose language understanding systems},
  author={Wang, Alex and Pruksachatkun, Yada and Nangia, Nikita and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019}
}

@inproceedings{sathe2020automated,
  title={Automated fact-checking of claims from wikipedia},
  author={Sathe, Aalok and Ather, Salar and Le, Tuan Manh and Perry, Nathan and Park, Joonsuk},
  booktitle={Proceedings of the 12th Language Resources and Evaluation Conference},
  pages={6874--6882},
  year={2020}
}

@article{nie2019adversarial,
  title={Adversarial NLI: A new benchmark for natural language understanding},
  author={Nie, Yixin and Williams, Adina and Dinan, Emily and Bansal, Mohit and Weston, Jason and Kiela, Douwe},
  journal={arXiv preprint arXiv:1910.14599},
  year={2019}
}

@article{liu2019roberta,
  title={Roberta: A robustly optimized bert pretraining approach},
  author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1907.11692},
  year={2019}
}

@article{he2020deberta,
  title={Deberta: Decoding-enhanced bert with disentangled attention},
  author={He, Pengcheng and Liu, Xiaodong and Gao, Jianfeng and Chen, Weizhu},
  journal={arXiv preprint arXiv:2006.03654},
  year={2020}
}

@article{petrov2011universal,
  title={A universal part-of-speech tagset},
  author={Petrov, Slav and Das, Dipanjan and McDonald, Ryan},
  journal={arXiv preprint arXiv:1104.2086},
  year={2011}
}

@misc{jackroos2019,
  author = {Weijie Su},
  title = {Pythia},
  year = {2019},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/jackroos/pythia}},
  commit = {12f67cd4f67499814bb0b3665ff14dd635800f63}
}

@inproceedings{zhang2023practice,
  title={How to Practice VQA on a Resource-limited Target Domain},
  author={Zhang, Mingda and Hwa, Rebecca and Kovashka, Adriana},
  booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
  pages={4451--4460},
  year={2023}
}

@article{xu2023question,
  title={A question-guided multi-hop reasoning graph network for visual question answering},
  author={Xu, Zhaoyang and Gu, Jinguang and Liu, Maofu and Zhou, Guangyou and Fu, Haidong and Qiu, Chen},
  journal={Information Processing \& Management},
  volume={60},
  number={2},
  pages={103207},
  year={2023},
  publisher={Elsevier}
}
