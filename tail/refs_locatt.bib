@book{miller2003encyclopedia,
	title={Encyclopedia \& Dictionary of Medicine, Nursing, \& Allied Health Seventh Edition},
	author={Miller-Keane},
	year={2003}
}


@article{he2015deep,
	title={Deep Residual Learning for Image Recognition},
	author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	journal={arXiv preprint arXiv:1512.03385},
	year={2015}
}

% ------------------------------------------------------------
Localized Quesitons in Medical Visual Question Answering

@inproceedings{tascon2023localized,
  title={Localized Questions in Medical Visual Question Answering},
  author={Tascon-Morales, Sergio and M{\'a}rquez-Neila, Pablo and Sznitman, Raphael},
  booktitle={International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages={361--370},
  year={2023},
  organization={Springer}
}




@inproceedings{selvaraju2020squinting,
  title={SQuINTing at VQA Models: Introspecting VQA Models With Sub-Questions},
  author={Selvaraju, Ramprasaath R and Tendulkar, Purva and Parikh, Devi and Horvitz, Eric and Ribeiro, Marco Tulio and Nushi, Besmira and Kamar, Ece},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={10003--10011},
  year={2020}
}


@inproceedings{ribeiro2019red,
  title={Are red roses red? evaluating consistency of question-answering models},
  author={Ribeiro, Marco Tulio and Guestrin, Carlos and Singh, Sameer},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  pages={6174--6184},
  year={2019}
}

@InProceedings{Nguyen19,
author="Nguyen, Binh D.
and Do, Thanh-Toanidrid
and Nguyen, Binh X.
and Do, Tuong
and Tjiputra, Erman
and Tran, Quang D.",
editor="Shen, Dinggang
and Liu, Tianming
and Peters, Terry M.
and Staib, Lawrence H.
and Essert, Caroline
and Zhou, Sean
and Yap, Pew-Thian
and Khan, Ali",
title="Overcoming Data Limitation in Medical Visual Question Answering",
booktitle="Medical Image Computing and Computer Assisted Intervention -- MICCAI 2019",
year="2019",
publisher="Springer International Publishing",
address="Cham",
pages="522--530",
abstract="Traditional approaches for Visual Question Answering (VQA) require large amount of labeled data for training. Unfortunately, such large scale data is usually not available for medical domain. In this paper, we propose a novel medical VQA framework that overcomes the labeled data limitation. The proposed framework explores the use of the unsupervised Denoising Auto-Encoder (DAE) and the supervised Meta-Learning. The advantage of DAE is to leverage the large amount of unlabeled images while the advantage of Meta-Learning is to learn meta-weights that quickly adapt to VQA problem with limited labeled data. By leveraging the advantages of these techniques, it allows the proposed framework to be efficiently trained using a small labeled training set. The experimental results show that our proposed method significantly outperforms the state-of-the-art medical VQA. The source code is available at https://github.com/aioz-ai/MICCAI19-MedVQA.",
isbn="978-3-030-32251-9"
}



@article{ray2019sunny,
  title={Sunny and dark outside?! improving answer consistency in vqa through entailed question generation},
  author={Ray, Arijit and Sikka, Karan and Divakaran, Ajay and Lee, Stefan and Burachas, Giedrius},
  journal={arXiv preprint arXiv:1909.04696},
  year={2019}
}

@inproceedings{shah2019cycle,
  title={Cycle-consistency for robust visual question answering},
  author={Shah, Meet and Chen, Xinlei and Rohrbach, Marcus and Parikh, Devi},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={6649--6658},
  year={2019}
}

@article{teney2019incorporating,
  title={On incorporating semantic prior knowledge in deep learning through embedding-space constraints},
  author={Teney, Damien and Abbasnejad, Ehsan and Hengel, Anton van den},
  journal={arXiv preprint arXiv:1909.13471},
  year={2019}
}

@inproceedings{gokhale2020vqa,
  title={{VQA-LOL}: Visual question answering under the lens of logic},
  author={Gokhale, Tejas and Banerjee, Pratyay and Baral, Chitta and Yang, Yezhou},
  booktitle={European conference on computer vision},
  pages={379--396},
  year={2020},
  organization={Springer}
}

@article{kil2021discovering,
  title={Discovering the Unknown Knowns: Turning Implicit Knowledge in the Dataset into Explicit Training Examples for Visual Question Answering},
  author={Kil, Jihyung and Zhang, Cheng and Xuan, Dong and Chao, Wei-Lun},
  journal={arXiv preprint arXiv:2109.06122},
  year={2021}
}

@article{idrid,
doi = {10.21227/H25W98},
url = {https://dx.doi.org/10.21227/H25W98},
author = {Porwal, Prasanna and Pachade, Samiksha and Kamble, Ravi and Kokare, Manesh and Deshmukh, Girish and Sahasrabuddhe, Vivek and Meriaudeau, Fabrice},
publisher = {IEEE Dataport},
title = {Indian Diabetic Retinopathy Image Dataset (IDRiD)},
year = {2018} } 

@article{decenciere2013teleophta,
  title={TeleOphta: Machine learning and image processing methods for teleophthalmology},
  author={Decenciere, Etienne and Cazuguel, Guy and Zhang, Xiwei and Thibault, Guillaume and Klein, J-C and Meyer, Fernand and Marcotegui, Beatriz and Quellec, Gw{\'e}nol{\'e} and Lamard, Mathieu and Danno, Ronan and others},
  journal={Irbm},
  volume={34},
  number={2},
  pages={196--203},
  year={2013},
  publisher={Elsevier}
}

@inproceedings{goel2021iq,
  title={{IQ-VQA}: Intelligent Visual Question Answering},
  author={Goel, Vatsal and Chandak, Mohit and Anand, Ashish and Guha, Prithwijit},
  booktitle={International Conference on Pattern Recognition},
  pages={357--370},
  year={2021},
  organization={Springer}
}

@inproceedings{antol2015vqa,
  title={Vqa: Visual question answering},
  author={Antol, Stanislaw and Agrawal, Aishwarya and Lu, Jiasen and Mitchell, Margaret and Batra, Dhruv and Zitnick, C Lawrence and Parikh, Devi},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2425--2433},
  year={2015}
}

@article{mani2020point,
  title={Point and ask: Incorporating pointing into visual question answering},
  author={Mani, Arjun and Yoo, Nobline and Hinthorn, Will and Russakovsky, Olga},
  journal={arXiv preprint arXiv:2011.13681},
  year={2020}
}



@inproceedings{niu2021counterfactual,
  title={Counterfactual vqa: A cause-effect look at language bias},
  author={Niu, Yulei and Tang, Kaihua and Zhang, Hanwang and Lu, Zhiwu and Hua, Xian-Sheng and Wen, Ji-Rong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={12700--12710},
  year={2021}
}
@inproceedings{goyal2017making,
  title={Making the v in vqa matter: Elevating the role of image understanding in visual question answering},
  author={Goyal, Yash and Khot, Tejas and Summers-Stay, Douglas and Batra, Dhruv and Parikh, Devi},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={6904--6913},
  year={2017}
}

@inproceedings{kv2020reducing,
  title={Reducing language biases in visual question answering with visually-grounded question encoder},
  author={KV, Gouthaman and Mittal, Anurag},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XIII 16},
  pages={18--34},
  year={2020},
  organization={Springer}
}

@inproceedings{zhu2016visual7w,
  title={Visual7w: Grounded question answering in images},
  author={Zhu, Yuke and Groth, Oliver and Bernstein, Michael and Fei-Fei, Li},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={4995--5004},
  year={2016}
}

@article{hudson2019gqa,
  title={Gqa: a new dataset for compositional question answering over real-world images},
  author={Hudson, Drew A and Manning, Christopher D},
  journal={arXiv preprint arXiv:1902.09506},
  volume={3},
  number={8},
  year={2019}
}
@inproceedings{agrawal2018don,
  title={Don't just assume; look and answer: Overcoming priors for visual question answering},
  author={Agrawal, Aishwarya and Batra, Dhruv and Parikh, Devi and Kembhavi, Aniruddha},
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},
  pages={4971--4980},
  year={2018}
}

@inproceedings{yuan2021perception,
  title={Perception Matters: Detecting Perception Failures of VQA Models Using Metamorphic Testing},
  author={Yuan, Yuanyuan and Wang, Shuai and Jiang, Mingyue and Chen, Tsong Yueh},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={16908--16917},
  year={2021}
}

@article{tan2019lxmert,
  title={Lxmert: Learning cross-modality encoder representations from transformers},
  author={Tan, Hao and Bansal, Mohit},
  journal={arXiv preprint arXiv:1908.07490},
  year={2019}
}


@article{vu2020question,
  title={A question-centric model for visual question answering in medical imaging},
  author={Vu, Minh H and L{\"o}fstedt, Tommy and Nyholm, Tufve and Sznitman, Raphael},
  journal={IEEE transactions on medical imaging},
  volume={39},
  number={9},
  pages={2856--2868},
  year={2020},
  publisher={IEEE}
}
@article{ramakrishnan2018overcoming,
  title={Overcoming language priors in visual question answering with adversarial regularization},
  author={Ramakrishnan, Sainandan and Agrawal, Aishwarya and Lee, Stefan},
  journal={arXiv preprint arXiv:1810.03649},
  year={2018}
}

@article{cadene2019rubi,
  title={Rubi: Reducing unimodal biases for visual question answering},
  author={Cadene, Remi and Dancette, Corentin and Cord, Matthieu and Parikh, Devi and others},
  journal={Advances in neural information processing systems},
  volume={32},
  pages={841--852},
  year={2019}
}

@article{clark2019don,
  title={Don't take the easy way out: Ensemble based methods for avoiding known dataset biases},
  author={Clark, Christopher and Yatskar, Mark and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1909.03683},
  year={2019}
}
@article{ren2018diabetic,
  title={Diabetic macular edema grading in retinal images using vector quantization and semi-supervised learning},
  author={Ren, Fulong and Cao, Peng and Zhao, Dazhe and Wan, Chao},
  journal={Technology and Health Care},
  volume={26},
  number={S1},
  pages={389--397},
  year={2018},
  publisher={IOS Press}
}
@article{jiang2018pythia,
  title={Pythia v0. 1: the winning entry to the vqa challenge 2018},
  author={Jiang, Yu and Natarajan, Vivek and Chen, Xinlei and Rohrbach, Marcus and Batra, Dhruv and Parikh, Devi},
  journal={arXiv preprint arXiv:1807.09956},
  year={2018}
}

@article{gupta2021hierarchical,
  title={Hierarchical deep multi-modal network for medical visual question answering},
  author={Gupta, Deepak and Suman, Swati and Ekbal, Asif},
  journal={Expert Systems with Applications},
  volume={164},
  pages={113993},
  year={2021},
  publisher={Elsevier}
}
@inproceedings{zhan2020medical,
  title={Medical visual question answering via conditional reasoning},
  author={Zhan, Li-Ming and Liu, Bo and Fan, Lu and Chen, Jiaxin and Wu, Xiao-Ming},
  booktitle={Proceedings of the 28th ACM International Conference on Multimedia},
  pages={2345--2354},
  year={2020}
}

@article{hochreiter1997long,
  title={Long short-term memory},
  author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
  journal={Neural computation},
  volume={9},
  number={8},
  pages={1735--1780},
  year={1997},
  publisher={MIT Press}
}

@inproceedings{xu2015show,
  title={Show, attend and tell: Neural image caption generation with visual attention},
  author={Xu, Kelvin and Ba, Jimmy and Kiros, Ryan and Cho, Kyunghyun and Courville, Aaron and Salakhudinov, Ruslan and Zemel, Rich and Bengio, Yoshua},
  booktitle={International conference on machine learning},
  pages={2048--2057},
  year={2015},
  organization={PMLR}
}

@article{kim2016hadamard,
  title={Hadamard product for low-rank bilinear pooling},
  author={Kim, Jin-Hwa and On, Kyoung-Woon and Lim, Woosang and Kim, Jeonghee and Ha, Jung-Woo and Zhang, Byoung-Tak},
  journal={arXiv preprint arXiv:1610.04325},
  year={2016}
}

@inproceedings{yu2017multi,
  title={Multi-modal factorized bilinear pooling with co-attention learning for visual question answering},
  author={Yu, Zhou and Yu, Jun and Fan, Jianping and Tao, Dacheng},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={1821--1830},
  year={2017}
}

@article{yu2018beyond,
  title={Beyond bilinear: Generalized multimodal factorized high-order pooling for visual question answering},
  author={Yu, Zhou and Yu, Jun and Xiang, Chenchao and Fan, Jianping and Tao, Dacheng},
  journal={IEEE transactions on neural networks and learning systems},
  volume={29},
  number={12},
  pages={5947--5959},
  year={2018},
  publisher={IEEE}
}

@article{fukui2016multimodal,
  title={Multimodal compact bilinear pooling for visual question answering and visual grounding},
  author={Fukui, Akira and Park, Dong Huk and Yang, Daylen and Rohrbach, Anna and Darrell, Trevor and Rohrbach, Marcus},
  journal={arXiv preprint arXiv:1606.01847},
  year={2016}
}

@Inproceedings{ImageCLEFVQA_Med2018,
author = {Sadid A. Hasan and Yuan Ling and Oladimeji Farri and Joey Liu and Matthew Lungren and Henning M\"uller},
title = {Overview of the {ImageCLEF} 2018 Medical Domain Visual Question Answering Task},
booktitle = {CLEF2018 Working Notes},
series = {{CEUR} Workshop Proceedings},
year = {2018},
volume = {},
publisher = {CEUR-WS.org $<$http://ceur-ws.org$>$},
pages = {},
month = {9},
address = {Avignon, France},
}

@inproceedings{ben2017mutan,
  title={Mutan: Multimodal tucker fusion for visual question answering},
  author={Ben-Younes, Hedi and Cadene, R{\'e}mi and Cord, Matthieu and Thome, Nicolas},
  booktitle={Proceedings of the IEEE international conference on computer vision},
  pages={2612--2620},
  year={2017}
}

@inproceedings{liu2019effective,
  title={An effective deep transfer learning and information fusion framework for medical visual question answering},
  author={Liu, Feifan and Peng, Yalei and Rosen, Max P},
  booktitle={International Conference of the Cross-Language Evaluation Forum for European Languages},
  pages={238--247},
  year={2019},
  organization={Springer}
}

@inproceedings{sarrouti2020nlm,
  title={NLM at VQA-Med 2020: Visual Question Answering and Generation in the Medical Domain.},
  author={Sarrouti, Mourad},
  booktitle={CLEF (Working Notes)},
  year={2020}
}

@article{liao2020aiml,
  title={Aiml at vqa-med 2020: Knowledge inference via a skeleton-based sentence mapping approach for medical domain visual question answering},
  author={Liao, Zhibin and Wu, Qi and Shen, Chunhua and Van Den Hengel, Anton and Verjans, Johan},
  year={2020},
  publisher={CEUR-WS}
}

@inproceedings{anderson2018bottom,
  title={Bottom-up and top-down attention for image captioning and visual question answering},
  author={Anderson, Peter and He, Xiaodong and Buehler, Chris and Teney, Damien and Johnson, Mark and Gould, Stephen and Zhang, Lei},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={6077--6086},
  year={2018}
}

@inproceedings{zhou2020unified,
  title={Unified vision-language pre-training for image captioning and vqa},
  author={Zhou, Luowei and Palangi, Hamid and Zhang, Lei and Hu, Houdong and Corso, Jason and Gao, Jianfeng},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={07},
  pages={13041--13049},
  year={2020}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@inproceedings{johnson2017clevr,
  title={Clevr: A diagnostic dataset for compositional language and elementary visual reasoning},
  author={Johnson, Justin and Hariharan, Bharath and Van Der Maaten, Laurens and Fei-Fei, Li and Lawrence Zitnick, C and Girshick, Ross},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={2901--2910},
  year={2017}
}

@inproceedings{abacha2018nlm,
  title={NLM at ImageCLEF 2018 Visual Question Answering in the Medical Domain.},
  author={Abacha, Asma Ben and Gayen, Soumya and Lau, Jason J and Rajaraman, Sivaramakrishnan and Demner-Fushman, Dina},
  booktitle={CLEF (Working Notes)},
  year={2018}
}
@inproceedings{zhou2018employing,
  title={Employing Inception-Resnet-v2 and Bi-LSTM for Medical Domain Visual Question Answering.},
  author={Zhou, Yangyang and Kang, Xin and Ren, Fuji},
  booktitle={CLEF (Working Notes)},
  year={2018}
}

@article{kornuta2019leveraging,
  title={Leveraging medical visual question answering with supporting facts},
  author={Kornuta, Tomasz and Rajan, Deepta and Shivade, Chaitanya and Asseman, Alexis and Ozcan, Ahmet S},
  journal={arXiv preprint arXiv:1905.12008},
  year={2019}
}

@inproceedings{gong2021cross,
  title={Cross-Modal Self-Attention with Multi-Task Pre-Training for Medical Visual Question Answering},
  author={Gong, Haifan and Chen, Guanqi and Liu, Sishuo and Yu, Yizhou and Li, Guanbin},
  booktitle={Proceedings of the 2021 International Conference on Multimedia Retrieval},
  pages={456--460},
  year={2021}
}

@inproceedings{tascon2022consistency,
  title={Consistency-Preserving Visual Question Answering in Medical Imaging},
  author={Tascon-Morales, Sergio and M{\'a}rquez-Neila, Pablo and Sznitman, Raphael},
  booktitle={Medical Image Computing and Computer Assisted Intervention--MICCAI 2022: 25th International Conference, Singapore, September 18--22, 2022, Proceedings, Part VIII},
  pages={386--395},
  year={2022},
  organization={Springer}
}

@article{allan20192017,
  title={2017 robotic instrument segmentation challenge},
  author={Allan, Max and Shvets, Alex and Kurmann, Thomas and Zhang, Zichen and Duggal, Rahul and Su, Yun-Hsuan and Rieke, Nicola and Laina, Iro and Kalavakonda, Niveditha and Bodenstedt, Sebastian and others},
  journal={arXiv preprint arXiv:1902.06426},
  year={2019}
}

@inproceedings{fox2020insegcat,
  author    = {Markus Fox and
               Mario Taschwer and
               Klaus Schoeffmann},
  editor    = {Alba Garc{\'{\i}}a Seco de Herrera and
               Alejandro Rodr{\'{\i}}guez Gonz{\'{a}}lez and
               K. C. Santosh and
               Zelalem Temesgen and
               Bridget Kane and
               Paolo Soda},
  title     = {Pixel-Based Tool Segmentation in Cataract Surgery Videos with Mask
               {R-CNN}},
  booktitle = {33rd {IEEE} International Symposium on Computer-Based Medical Systems,
                {CBMS} 2020, Rochester, MN, USA, July 28-30, 2020},
  pages     = {565--568},
  publisher = {{IEEE}},
  year      = {2020},
  url       = {https://doi.org/10.1109/CBMS49503.2020.00112},
  doi       = {10.1109/CBMS49503.2020.00112},
  timestamp = {Thu, 10 Sep 2020 16:38:14 +0200},
  biburl    = {https://dblp.org/rec/conf/cbms/FoxTS20.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{grammatikopoulou2019cadis,
  title={Cadis: Cataract dataset for image segmentation},
  author={Grammatikopoulou, Maria and Flouty, Evangello and Kadkhodamohammadi, Abdolrahim and Quellec, Gwenol'e and Chow, Andre and Nehme, Jean and Luengo, Imanol and Stoyanov, Danail},
  journal={arXiv preprint arXiv:1906.11586},
  year={2019}
}

@article{yu2023question,
  title={Question-guided feature pyramid network for medical visual question answering},
  author={Yu, Yonglin and Li, Haifeng and Shi, Hanrong and Li, Lin and Xiao, Jun},
  journal={Expert Systems with Applications},
  volume={214},
  pages={119148},
  year={2023},
  publisher={Elsevier}
}

@article{ren2020cgmvqa,
  title={Cgmvqa: A new classification and generative model for medical visual question answering},
  author={Ren, Fuji and Zhou, Yangyang},
  journal={IEEE Access},
  volume={8},
  pages={50626--50636},
  year={2020},
  publisher={IEEE}
}

@inproceedings{liu2021slake,
  title={Slake: A semantically-labeled knowledge-enhanced dataset for medical visual question answering},
  author={Liu, Bo and Zhan, Li-Ming and Xu, Li and Ma, Lin and Yang, Yan and Wu, Xiao-Ming},
  booktitle={2021 IEEE 18th International Symposium on Biomedical Imaging (ISBI)},
  pages={1650--1654},
  year={2021},
  organization={IEEE}
}

@inproceedings{pelka2018radiology,
  title={Radiology Objects in COntext (ROCO): a multimodal image dataset},
  author={Pelka, Obioma and Koitka, Sven and R{\"u}ckert, Johannes and Nensa, Felix and Friedrich, Christoph M},
  booktitle={Intravascular Imaging and Computer Assisted Stenting and Large-Scale Annotation of Biomedical Data and Expert Label Synthesis: 7th Joint International Workshop, CVII-STENT 2018 and Third International Workshop, LABELS 2018, Held in Conjunction with MICCAI 2018, Granada, Spain, September 16, 2018, Proceedings 3},
  pages={180--189},
  year={2018},
  organization={Springer}
}

@inproceedings{do2021multiple,
  title={Multiple meta-model quantifying for medical visual question answering},
  author={Do, Tuong and Nguyen, Binh X and Tjiputra, Erman and Tran, Minh and Tran, Quang D and Nguyen, Anh},
  booktitle={Medical Image Computing and Computer Assisted Intervention--MICCAI 2021: 24th International Conference, Strasbourg, France, September 27--October 1, 2021, Proceedings, Part V 24},
  pages={64--74},
  year={2021},
  organization={Springer}
}



